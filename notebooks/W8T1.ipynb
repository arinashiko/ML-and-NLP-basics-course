{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "colab": {
   "name": "3_Students.ipynb",
   "provenance": [],
   "collapsed_sections": []
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TAyzWDzFdnLa"
   },
   "source": [
    "## Классификация текстов: Spam or Ham"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sh91cKPmdnLb"
   },
   "source": [
    "В этом задании на примере классического датасета Spambase Dataset (https://archive.ics.uci.edu/ml/datasets/spambase) мы попробуем сделать свой спам-фильтр c помощью библиотеки scikit-learn. Датасет содержит корпус текстов 5,574 смс с метками \"spam\" и \"ham\". "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D4Bf-AmgdnLb"
   },
   "source": [
    "-### Данные"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lWvXDXKrdnLb"
   },
   "source": [
    "Для удобства данные приложены в описании задания"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "UnJwvQzbdnLb",
    "ExecuteTime": {
     "start_time": "2023-05-25T07:57:27.167910Z",
     "end_time": "2023-05-25T07:57:27.227910Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('../data/W8T1/3_data.csv', encoding='latin-1')"
   ],
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GRqzedIIdnLc"
   },
   "source": [
    "Оставляем только интересующие нас колонки — тексты смс и метки:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "xO59-HEadnLc",
    "outputId": "470c6b7d-6e6f-4105-eab4-947debd213ef",
    "ExecuteTime": {
     "start_time": "2023-05-25T07:58:37.172946Z",
     "end_time": "2023-05-25T07:58:37.242946Z"
    }
   },
   "source": [
    "df = df[['v1', 'v2']]\n",
    "df = df.rename(columns = {'v1': 'label', 'v2': 'text'})\n",
    "df.head()"
   ],
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "  label                                               text\n0   ham  Go until jurong point, crazy.. Available only ...\n1   ham                      Ok lar... Joking wif u oni...\n2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n3   ham  U dun say so early hor... U c already then say...\n4   ham  Nah I don't think he goes to usf, he lives aro...",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ham</td>\n      <td>Go until jurong point, crazy.. Available only ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ham</td>\n      <td>Ok lar... Joking wif u oni...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>spam</td>\n      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ham</td>\n      <td>U dun say so early hor... U c already then say...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ham</td>\n      <td>Nah I don't think he goes to usf, he lives aro...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NU2xwmvIdnLd"
   },
   "source": [
    "Удаляем дублирующиеся тексты:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "iveCG_bXdnLd",
    "ExecuteTime": {
     "start_time": "2023-05-25T07:58:44.650417Z",
     "end_time": "2023-05-25T07:58:44.680418Z"
    }
   },
   "source": [
    "df = df.drop_duplicates('text')"
   ],
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XuPip3mzdnLd"
   },
   "source": [
    "Заменяем метки на бинарные:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "JsKdfy6-dnLd",
    "ExecuteTime": {
     "start_time": "2023-05-25T07:58:52.929195Z",
     "end_time": "2023-05-25T07:58:52.949194Z"
    }
   },
   "source": [
    "df['label'] = df['label'].map({'ham': 0, 'spam': 1})"
   ],
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8vQJK8LNdnLe"
   },
   "source": [
    "### Предобработка текста (Задание 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D8tefVdTdnLe"
   },
   "source": [
    "Нужно дополнить функцию для предобработки сообщений, которая делает с текстом следующее:\n",
    "* приводит текст к нижнему регистру;\n",
    "* удаляет стоп-слова;\n",
    "* удаляет знаки препинания;\n",
    "* нормализует текст при помощи стеммера Snowball.\n",
    "\n",
    "Предлагаем воспользоваться библиотекой nltk, чтобы не составлять список стоп-слов и не реализовывать алгоритм стемминга самостоятельно. Примеры использования стеммеров можно найти по ссылке (https://www.nltk.org/howto/stem.html)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "yhU1BvAHdnLe",
    "ExecuteTime": {
     "start_time": "2023-05-25T08:38:37.397925Z",
     "end_time": "2023-05-25T08:38:37.427964Z"
    }
   },
   "source": [
    "import nltk\n",
    "from nltk import stem\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "\n",
    "nltk.download(\"stopwords\")\n",
    "\n",
    "stemmer = stem.SnowballStemmer('english')\n",
    "stopwords = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess(text: str):\n",
    "    text = re.sub(r'[^\\w\\s]', '', text) #only words left\n",
    "    text = text.lower()\n",
    "    text_split = text.split(' ')\n",
    "    text_split = list(filter(lambda x : x not in stopwords, text_split))\n",
    "    text_norm = map(lambda x : stemmer.stem(x), text_split)\n",
    "\n",
    "    return ' '.join(text_norm)"
   ],
   "execution_count": 12,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\arbyz\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QM-Lrt6ddnLe"
   },
   "source": [
    "Проверка, что функция работает верно"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "RSuPqUb2dnLe",
    "ExecuteTime": {
     "start_time": "2023-05-25T08:38:45.004203Z",
     "end_time": "2023-05-25T08:38:45.024202Z"
    }
   },
   "source": [
    "assert preprocess(\"I'm gonna be home soon and i don't want to talk about this stuff anymore tonight, k? I've cried enough today.\") == \"im gonna home soon dont want talk stuff anymor tonight k ive cri enough today\"\n",
    "assert preprocess(\"Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...\") == \"go jurong point crazi avail bugi n great world la e buffet cine got amor wat\""
   ],
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "84H8mOmpdnLe"
   },
   "source": [
    "Применяем получившуюся функцию к текстам:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "NtM4626ednLe",
    "ExecuteTime": {
     "start_time": "2023-05-25T08:40:17.163529Z",
     "end_time": "2023-05-25T08:40:18.477317Z"
    }
   },
   "source": [
    "df['text'] = df['text'].apply(preprocess)"
   ],
   "execution_count": 14,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gRyqtqUtdnLe"
   },
   "source": [
    "### Разделение данных на обучающую и тестовую выборки (Задание 2)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "nt7Z5NCMdnLe",
    "ExecuteTime": {
     "start_time": "2023-05-25T08:40:57.297892Z",
     "end_time": "2023-05-25T08:40:57.339917Z"
    }
   },
   "source": [
    "y = df['label'].values"
   ],
   "execution_count": 15,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6r4PJBctdnLe"
   },
   "source": [
    "Теперь нужно разделить данные на тестовую (test) и обучающую (train) выборку. В библиотеке scikit-learn для этого есть готовые инструменты."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "r1c9ARWIdnLe",
    "ExecuteTime": {
     "start_time": "2023-05-25T08:47:16.605699Z",
     "end_time": "2023-05-25T08:47:16.665766Z"
    }
   },
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['text'], y, test_size=0.2, random_state=41)"
   ],
   "execution_count": 23,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KOV7Ub4ldnLe"
   },
   "source": [
    "### Обучение классификатора (Задание 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "enAzNefqdnLe"
   },
   "source": [
    "Переходим к обучению классификатора.\n",
    "\n",
    "Сначала извлекаем признаки из текстов. Рекомендуем попробовать разные способы и посмотреть, как это влияет на результат (подробнее о различных способах представления текстов можно прочитать по ссылке https://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction).\n",
    "\n",
    "Затем обучаем классификатор. Мы используем SVM, но можно поэкспериментировать с различными алгоритмами."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "QtfcmJ7NdnLe",
    "ExecuteTime": {
     "start_time": "2023-05-25T08:47:29.119590Z",
     "end_time": "2023-05-25T08:47:29.198833Z"
    }
   },
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "# извлекаем признаки из текстов\n",
    "vectorizer = TfidfVectorizer(decode_error='ignore')\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)"
   ],
   "execution_count": 24,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "PIQQo8j3dnLe",
    "ExecuteTime": {
     "start_time": "2023-05-25T08:47:41.459236Z",
     "end_time": "2023-05-25T08:47:41.482419Z"
    }
   },
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#обучаем подель SVM\n",
    "\n",
    "model = LinearSVC(random_state = 41, C = 1.1)\n",
    "model.fit(X_train, y_train)\n",
    "predictions = model.predict(X_test)"
   ],
   "execution_count": 25,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sn9kvQaZdnLe"
   },
   "source": [
    "Для самопроверки. Если вы верно дополнили функцию ```preprocess```, то должны получиться следующие результаты оценки модели."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "zGxDEYnjdnLe",
    "outputId": "104a68f1-cf8a-421e-cc3f-2b63b99c2520",
    "ExecuteTime": {
     "start_time": "2023-05-25T08:48:03.871141Z",
     "end_time": "2023-05-25T08:48:03.901317Z"
    }
   },
   "source": [
    "print(classification_report(y_test, predictions, digits=3))"
   ],
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.977     0.994     0.986       898\n",
      "           1      0.958     0.846     0.898       136\n",
      "\n",
      "    accuracy                          0.975      1034\n",
      "   macro avg      0.968     0.920     0.942      1034\n",
      "weighted avg      0.975     0.975     0.974      1034\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1nffLu6UdnLf"
   },
   "source": [
    "Выполним предсказание для конкретного текста"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "prWswDzudnLf",
    "ExecuteTime": {
     "start_time": "2023-05-25T08:46:16.002415Z",
     "end_time": "2023-05-25T08:46:16.022415Z"
    }
   },
   "source": [
    "txt = \"As a valued customer, I am pleased to advise you that following recent review of your Mob No. you are awarded with a å£1500 Bonus Prize, call 09066364589\"\n",
    "txt = preprocess(txt)\n",
    "txt = vectorizer.transform([txt])"
   ],
   "execution_count": 21,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "brfpnzR7dnLf",
    "outputId": "5220b6fe-a3a6-45f4-e726-b3f813ac7751",
    "ExecuteTime": {
     "start_time": "2023-05-25T08:46:20.792792Z",
     "end_time": "2023-05-25T08:46:20.805025Z"
    }
   },
   "source": [
    "model.predict(txt)"
   ],
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "array([1], dtype=int64)"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "aVfQFiwGdnLf"
   },
   "source": [
    "#Сообщение помечено как спам."
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0, 0, 0, 1], dtype=int64)"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = ['Get SMART Spam Control That Always Delivers The Email You Want! Finally, we discovered the ultimate solution that is guaranteed to stop all spam without losing any of your important email!', 'This is a fine collection of articles by Bernard Lewis about the Middle East.', 'Reduce your mortgage payments Interest Rates are Going Up! Give Your Family The Financial freedom They Deserve Refinance Today and SAVE', 'Take your prize, more than 100 computers, smartphones and TVs are supposed to be played in a free quiz. Call by phone 8 800 243 456']\n",
    "\n",
    "preprocessed_test_data = list(map(lambda x: preprocess(x), test_data))\n",
    "vectorized_test_data = vectorizer.transform(preprocessed_test_data)\n",
    "model.predict(vectorized_test_data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-25T08:57:40.706138Z",
     "end_time": "2023-05-25T08:57:40.786137Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ]
}
